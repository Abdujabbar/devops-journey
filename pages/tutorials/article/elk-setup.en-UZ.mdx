import { Callout } from "nextra-theme-docs";

# ELK Stack Cluster o'rnatish va sozlash

![elk-setup](public/images/article/elk-setup/banner.png)

Oldingi [**ELK Stackga kirish**](https://devops-journey.uz/tutorials/article/elk-stack) mavzusida biz ELK nimaga ishlatilishi uning arxitekturasi va componentlari, qanday ishlashini ko'rib chiqgan edik. Bugungi amaliyotimizda biz ELK stack deploy qilishni ko'rib chiqamiz.
<Callout type="info" emoji="">
**Diqqat!** 
* Ushbu amaliyotni boshlash uchun [**ELK Stackga kirish**](https://devops-journey.uz/tutorials/article/elk-stack) qo'llanmasini o'qib chiqgan bo'lishingiz kerak bo'ladi.
* Ushbu amaliyotda biz **Elasticsearch** `7.17` versiyasidan foydalanamiz!
</Callout>

## Arxitektura

Ushbu amaliyotda biz kichik ELK stack cluster o'rnatib sozlayymiz. ELK stack uchun minmum 3ta server va ELK stack bilan ishlash uchun bitta app server kerak bo'ladi. Clusterdagi barcha serverlar bitta subnetda bo'lishi kerak bo'ladi chunki ELK componentlar bir bir bilan Internal IPlar bilan bo'glanib ishlaydi. ELK stack commentlari uchun 3ta alohida serverda sozlanadi Elasticsearch, Kibana va Logstash. Boshqa serverlarga Beatslar o'ratiladi, ba'zi beatslar loglarni logstashga yuboradi va logstash ular ustida ishlab uni elasticsearchga yuboradi, elasticsearchdan esa Kibana UI Dashboard orqali vizualizatsiya qilib monitoring ava analiz qilmaiz. Ba'zi beatlar va Integrationlar esa to'gridan-to'gri malumotlarni elasticsearchga yuboradi.  

Bugungi amaliyotda rasmda ko'rsatilgan ELK clusterni o'rnatib sozlaymiz.

![elk-setup](public/images/article/elk-setup/architecture.png)
## Ishni boshlash

Ushbu amaliyotni amalga oshirish uchun bizga quyidagi minimum server talablaridagi server kerak bo'ladi.

<Callout type="info" emoji="">
**Minimum Server talabi**

| Host        | OS            | RAM            | CPU           | Xotira       | IP          |
| ----------- | ------------- | -------------- | ------------- |------------- | ----------- |
|  elk        | Ubuntu 20.04  | 16GB           | 4vCPU,2 core  | 100GB        | 10.128.0.9  |
|  kibana     | Ubuntu 20.04  | 4GB            | 2vCPU,1 core  | 50GB         | 10.128.0.10 |
|  logstash   | Ubuntu 20.04  | 16GB           | 2vCPU,1 core  | 50GB         | 10.128.0.11 |
|  app-server | Ubuntu 20.04  | 16GB           | 2vCPU,1 core  | 50GB         | 10.128.0.12 |

![elk-setup](public/images/article/elk-setup/vm.png)
</Callout>

## Elasticsearch o'rnatish

Elasticsearcni Debian based serverlarga o'rnatish, Ubuntuga ham mos keladi.

**1->** `elk`(10.128.0.9) serverimizni yangilab kerakli dasturlarni o'rnatib olamiz.

```bash
sudo apt update && sudo apt upgrade -y
sudo apt-get install apt-transport-https
```

**2->** Elasticsearch PGP Keyini import qilib olamiz.

```bash
wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo gpg --dearmor -o /usr/share/keyrings/elasticsearch-keyring.gpg
```

**3->** `/etc/apt/sources.list.d`ga elasticsearchni qo'shib qo'yamiz.

```bash
echo "deb [signed-by=/usr/share/keyrings/elasticsearch-keyring.gpg] https://artifacts.elastic.co/packages/7.x/apt stable main" | sudo tee /etc/apt/sources.list.d/elastic-7.x.list
```

**4->** Elasticsearcni o'rnatib olamiz.

```bash
sudo apt-get update && sudo apt-get install elasticsearch
```

`elasticsearch.yml` konfiguratsiyadan elasticsearchni tashqariga ochamiz.

```bash
sudo nano /etc/elasticsearch/elasticsearch.yml
```

```bash {6,11,24}
# ---------------------------------- Network -----------------------------------
#
# By default Elasticsearch is only accessible on localhost. Set a different
# address here to expose this node on the network:
#
network.host: 0.0.0.0
#
# By default Elasticsearch listens for HTTP traffic on the first free port it
# finds starting at 9200. Set a specific HTTP port here:
#
http.port: 9200
#
# For more information, consult the network module documentation.
#
# --------------------------------- Discovery ----------------------------------
#
# Pass an initial list of hosts to perform discovery when this node is started:
# The default list of hosts is ["127.0.0.1", "[::1]"]
#
#discovery.seed_hosts: ["host1", "host2"]
#
# Bootstrap the cluster using an initial set of master-eligible nodes:
#
cluster.initial_master_nodes: ["127.0.0.1"]
```

**5->** Elasticsearchni ishga tushiramiz.

daemonni reload qilamiz.

```bash
sudo systemctl daemon-reload
```

Elasticsearchni systemd yordamida avtomatik ishga tushishini yoqamiz.

```bash
sudo systemctl enable elasticsearch.service
```
Elasticsearchni ishga tushiramiz va statusini ko'ramiz.

```bash
sudo systemctl start elasticsearch.service
sudo systemctl status elasticsearch.service
```
![elk-setup](public/images/article/elk-setup/systemd.png)

Keling resurs ishlatilishini ko'ramiz.

```bash
htop
```
![elk-setup](public/images/article/elk-setup/htop.png)

hahaaa resurs RAM usage 8.53GB ))

**6->** Elasticsearch ishlayotganini bilish uchun elastic ishlab turgan subnetdagi birorta serverdan  elasticsearch serverga `"10.128.0.9:9200`ga HTTP request yuborib ko'ramiz. Masalan logstash serverdan.

```bash
curl -X GET "10.128.0.9:9200"
```

![elk-setup](public/images/article/elk-setup/curl.png)
Sizda yuqoridagidek natija chiqsa Elasticsearch ishlamoqda.

## Kibana o'rnatish

[Rasmiy texnik hujjatlarga](https://www.elastic.co/guide/en/elastic-stack/current/installing-elastic-stack.html#install-order-elastic-stack) ko'ra , siz **Kibana**-ni faqat **Elasticsearch**-ni o'rnatganingizdan so'ng o'rnatishingiz kerak. Ushbu tartibda o'rnatish har bir productga bog'liq bo'lgan komponentlarning to'g'ri o'rnatilishini ta'minlaydi.



**1->** `kibana`(10.128.0.10) serverimizni yangilab kerakli dasturlarni o'rnatib olamiz.

```bash
sudo apt update && sudo apt upgrade -y
sudo apt-get install apt-transport-https
```

**2->** Elasticsearch PGP Keyini import qilib olamiz.

```bash
wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo gpg --dearmor -o /usr/share/keyrings/elasticsearch-keyring.gpg
```

**3->** `/etc/apt/sources.list.d`ga elasticsearchni qo'shib qo'yamiz.

```bash
echo "deb [signed-by=/usr/share/keyrings/elasticsearch-keyring.gpg] https://artifacts.elastic.co/packages/7.x/apt stable main" | sudo tee /etc/apt/sources.list.d/elastic-7.x.list
```

**4->** Kibanani o'rnatib olamiz.

```bash
sudo apt-get update && sudo apt-get install kibana
```

**2->** Kibanani ishga tushiramiz.

daemonni reload qilamiz.

```bash
sudo systemctl daemon-reload
```
Kibanani systemd yordamida avtomatik ishga tushishini yoqamiz.

```bash
sudo systemctl enable kibana.service
```
Kibanani ishga tushiramiz va statusini ko'ramiz.

```bash
sudo systemctl start kibana.service
sudo systemctl status kibana.service
```
![elk-setup](public/images/article/elk-setup/systemd1.png)

**3->** Kibananin o'rnatib olganimizdan keyin tashqaridan brauzer orqali kirish uchun `/etc/kibana/kibana.yml` ni konfiguratsiya qilishimiz kerak va `elasticsearch.hosts` elasticsearch hostni belgilashimiz kerak.

```bash
sudo nano /etc/kibana/kibana.yml
```

```bash {2,7,9}
# Kibana is served by a back end server. This setting specifies the port to use.
server.port: 5601

# Specifies the address to which the Kibana server will bind. IP addresses and host names are both valid values.
# The default is 'localhost', which usually means remote machines will not be able to connect.
# To allow connections from remote users, set this parameter to a non-loopback address.
server.host: "0.0.0.0"
# The URLs of the Elasticsearch instances to use for all your queries.
elasticsearch.hosts: ["http://10.128.0.9:9200"]
```
Kibanaga restart beramiz.

```bash
sudo systemctl restart kibana.service
```

**4->** Kibana default `:5601` portda ishlaydi brauzerdan server IP adresi va `:5601` portga kirsak bizda Kibana dashboard ochilishi kerak.

![elk-setup](public/images/article/elk-setup/kibana.png)

Kibana dashboard statusini `:5601/status` pageda ko'rish mumkin.
![elk-setup](public/images/article/elk-setup/kibana-status.png)

## Logstash o'rnatish

**Beats** to'g'ridan-to'g'ri Elasticsearch ma'lumotlar bazasiga ma'lumotlarni yuborishi mumkin bo'lsa-da, ma'lumotlarni qayta ishlash uchun **Logstash**-dan foydalanish odatiy holdir. Bu sizga turli manbalardan ma'lumotlarni to'plash, ularni umumiy formatga aylantirish va boshqa ma'lumotlar bazasiga eksport qilish uchun ko'proq moslashuvchanlikni beradi.

**1->** `logstash`(10.128.0.11) serverimizni yangilab kerakli dasturlarni o'rnatib olamiz.

```bash
sudo apt update && sudo apt upgrade -y
sudo apt-get install apt-transport-https
```

**2->** Elasticsearch PGP Keyini import qilib olamiz.

```bash
wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo gpg --dearmor -o /usr/share/keyrings/elasticsearch-keyring.gpg
```

**3->** `/etc/apt/sources.list.d`ga elasticsearchni qo'shib qo'yamiz.

```bash
echo "deb [signed-by=/usr/share/keyrings/elasticsearch-keyring.gpg] https://artifacts.elastic.co/packages/7.x/apt stable main" | sudo tee /etc/apt/sources.list.d/elastic-7.x.list
```

**4->** Logstashni o'rnatib olamiz.

```bash
sudo apt-get update && sudo apt-get install logstash
```
Logstashni o'rnatib bo'lganingizdan keyin sozlashga o'tishingiz mumkin. Logstash konfigursatsiya fayli `/etc/logstash/conf.d` joylashgan bo'ladi bu konfiguratsiya sintaksissi haqida [quyidagi havola](https://www.elastic.co/guide/en/logstash/current/configuration-file-structure.html) orqali ko'rib chiqishingiz mumkin.

Logstashni ma'lumotlarni bir tomondan qabul qiladigan, u yoki bu tarzda qayta ishlab belgilangan joyga jo'natadigan pipeline deb tassavur qilsangiz bo'ladi. Logstash asosiy elementlari ikkita `input` va `output` qo'shimcha `filter`. `input` plaginlari manbadan ma'lumotlarni oladi, `filter` plaginlarini uni qayta ishlaydi va `output` plaginlari esa ma'lumotlarni belgilangan joyga yuboradi.

![elk-setup](public/images/article/elk-setup/logstash.png)

**2->** `02-beats-input.conf` nomli Filebeat inputni o'rnatadigan konfiguratsiya faylini yaratib olamiz.

```bash
sudo nano /etc/logstash/conf.d/02-beats-input.conf
```
Quyidagi konfiguratsiyani kiriting. Bu konfiguratsiya input konfiguratsiya hisoblanadi va `beats` TCP `5044` portida kirishni bildiradi.
```bash filename="/etc/logstash/conf.d/02-beats-input.conf"
input {
  beats {
    port => 5044
  }
}
```

**3->** Logstash beatslardan kelgan ma'lumotlarni Elasticsearch(`10.128.0.9:9200`) ga yuborishi uchun output konfiguratsiyani qo'shing. Bu Filebeat uchun.

```bash
sudo nano /etc/logstash/conf.d/30-elasticsearch-output.conf
```

```conf /10.128.0.9:9200/
output {
  if [@metadata][pipeline] {
	elasticsearch {
  	hosts => ["10.128.0.9:9200"]
  	manage_template => false
  	index => "%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}"
  	pipeline => "%{[@metadata][pipeline]}"
	}
  } else {
	elasticsearch {
  	hosts => ["10.128.0.9:9200"]
  	manage_template => false
  	index => "%{[@metadata][beat]}-%{[@metadata][version]}-%{+YYYY.MM.dd}"
	}
  }
}
```

**4->** Logstash konfiguratsiyani quyidagi buyruq bilan tekshirib ko'ring.

```bash
sudo -u logstash /usr/share/logstash/bin/logstash --path.settings /etc/logstash -t
```

Ushbu buyruq yozilgan konfiguratsiyani tekshirib chiqadi.

Agar sintaksis xatosi bo'lmasa sizda **"Config Validation Result: OK. Exiting Logstash"** natija chiqsa demak hammasi yaxshi. Agar konfiguratsiya testingiz muvaffaqiyatli o'tgan bo'lsa **Logstash**ni ishga tushirishingiz mumkin.

```bash
sudo systemctl start logstash
sudo systemctl enable logstash
```
Statusini ko'ramiz.

```bash
sudo systemctl status logstash
```

Logstash to'g'ri ishlayapti va to'liq sozlangan bo'lsa, **Filebeat**-ni o'rnatamiz.

## Filebeat o'rnatish va sozlash

**Elastic Stack** turli manbalardan ma'lumotlarni to'plash va ularni **Logstash** yoki **Elasticsearch**-ga o'tkazish uchun [**Beats**](https://www.elastic.co/beats) deb nomlangan bir nechta lightweight data shipperlardan foydalanadi.

Hozirda Elastic-dan mavjud bo'lgan Beatslar:

* [**Filebeat**](https://www.elastic.co/beats/filebeat) Log fayllarni to'playdi va jo'natadi.
* [**Metricbeat**](https://www.elastic.co/beats/metricbeat) Tizimlar va servicelar metrikalarni to'playdi va jo'natadi.
* [**Packetbeat**](https://www.elastic.co/beats/packetbeat) Tarmoq ma'lumotlarini to'playdi va jo'natadi.
* [**Auditbeat**](https://www.elastic.co/beats/auditbeat) Linux audit framework ma'lumotlarini to'playdi va jo'natadi
* [**Heartbeat**](https://www.elastic.co/observability/aiops) Servicelaringiz availability(mavjudligi)ni tekshirib turish orqali va nazorat qiladi.
* [**Winlogbeat**](https://www.elastic.co/beats/winlogbeat) Windows event loglarini to'playdi.

**Beats**lar haqida [ba'tafsil.](https://www.elastic.co/guide/en/beats/libbeat/8.13/getting-started.html)


Ushbu qo'llanmada biz **Filebeat** yordamida local loglarni Elastik stackga yo'naltiramiz.

**1->** `app-server`(10.128.0.12) serverimizni yangilab kerakli dasturlarni o'rnatib olamiz.

```bash
sudo apt update && sudo apt upgrade -y
sudo apt-get install apt-transport-https
```

**2->** Elasticsearch PGP Keyini import qilib olamiz.

```bash
wget -qO - https://artifacts.elastic.co/GPG-KEY-elasticsearch | sudo gpg --dearmor -o /usr/share/keyrings/elasticsearch-keyring.gpg
```

**3->** `/etc/apt/sources.list.d`ga elasticsearchni qo'shib qo'yamiz.

```bash
echo "deb [signed-by=/usr/share/keyrings/elasticsearch-keyring.gpg] https://artifacts.elastic.co/packages/7.x/apt stable main" | sudo tee /etc/apt/sources.list.d/elastic-7.x.list
```

**4->** Filebeatni o'rnatib olamiz.

```bash
sudo apt-get update && sudo apt-get install filebeat
```

**2->** Filebeat Logstashga ulanishi uchun `filebeat.yml` ni sozlab olamiz.

**Filebeat** ko'p chiqishlarni qo'llab quvvatlaydi lekin biz eventlarga qo'shimcha ishlov berish uchun Elasticsearch yoki Logstashga ma'lumotlarni yuboramiz. Bu qo'llanmada biz Filebeatdan yuborayotgan ma'lumotlarni to'gridan-to'gri Elasticsearch yubormaymiz, biz Filebeat yuborayotgan ma'lumotlarni boyitish va yaxshilash uchun Logstashni yuboramiz. Shuning uchun biz `filebeat.yml` konfiguratsiya faylidan ma'lumotlarni elasticsearchga yuborishni o'chirib qo'yib Logstashga yuborishni yoqib qo'yamiz.


Elasticsearchga ma'lumotlarni yuborishni o'chirib qo'yamiz. `output.elasticsearch:` va `hosts`ni commentga olib qo'yamiz.

```bash
sudo nano /etc/filebeat/filebeat.yml
```

```bash {2,4}
# ---------------------------- Elasticsearch Output ----------------------------
#output.elasticsearch:
  # Array of hosts to connect to.
#  hosts: ["localhost:9200"]
```

Filebeat ma'lumotlarni logstashga yuborish uchun Logstashga yuborishni yoqamiz. `output.logstash:` va `hosts`ni commentdan ochib qo'yamiz.


```bash {2,4}
# ------------------------------ Logstash Output -------------------------------
output.logstash:
  # The Logstash hosts
  hosts: ["10.128.0.11:5044"]
```

```bash {5,11}
# =================================== Kibana ===================================

# Starting with Beats version 6.0.0, the dashboards are loaded via the Kibana API.
# This requires a Kibana endpoint configuration.
setup.kibana:

  # Kibana Host
  # Scheme and port can be left out and will be set to the default (http and 5601)
  # In case you specify and additional path, the scheme is required: http://localhost:5601/path
  # IPv6 addresses should always be defined as: https://[2001:db8::1]:5601
  host: "10.128.0.10:5601"
```

Filebeatni kengaytirish uchun bir nechta [Filebeat modullari](https://www.elastic.co/guide/en/beats/filebeat/7.6/filebeat-modules.html) bor. Biz bu amaliyotda Filebeat **system** modulidan foydalanamiz, system moduli linux tizimining loglari va servicelar tomonidan yaratilgan loglarni to'playdi va analiz qiladi.

```bash
sudo filebeat modules enable system
```

Ushbu buyruq orqali yoqilgan va o'chirilgan modullar qo'yxatini ko'rishingiz mumkin.

```bash
sudo filebeat modules list
```
Quyidagicha natija chiqishi kerak.

```txt
Enabled:
system

Disabled:
activemq
apache
auditd
aws
awsfargate
azure
barracuda
bluecoat
cef
checkpoint
cisco
.........
```

Logstash Elasticsearchga ma'lumotlarni yuborishdan oldin Filebeatdan kelgan ma'lumotlarlarni tahlil qiladigan **Filebeat ingest pipeline** o'rnatishimiz kerak. **system** module uchun quyidagi buyruq orqali o'rantishingiz mumkin.

```bash
sudo filebeat setup --pipelines --modules system
```

Keyin esa index templateni Elasticsearchga qo'shish kerak.

Templateni qo'shish uchun quyidagi buyruqdan foydalaning.

```bash
sudo filebeat setup --index-management -E output.logstash.enabled=false -E 'output.elasticsearch.hosts=["localhost:9200"]'
```

```bash
Output
Index setup finished.
```

Filebeat o'zida Kibanada ma'lumotlarni ko'rish uchun Kibana dashboard bilan birga keladi. Dashboarddan foydalanishdan oldin index pattern yaratishimiz va Dashboardni Kibanaga o'rnatishimiz kerak bo'ladi.

Dashboard yoqilganda Filebeat versiya ma'lmotlarini tekshirish uchun Elasticsearchga ulanadi. Logstash yoqilganda dashboardni yuklash uchun Logstash chiqishini o'chirishingiz va Elasticsearch chiqishini yoqishingiz kerak. Bu bir necha daqiqa vaqt oladi.

```bash
sudo filebeat setup -E output.logstash.enabled=false -E output.elasticsearch.hosts=['localhost:9200'] -E setup.kibana.host=localhost:5601
```

Endi Filebeatni ishga tushirishimiz mumkin.

```bash
sudo systemctl start filebeat
sudo systemctl enable filebeat
```
Statusini tekshiramiz.
```bash
sudo systemctl status filebeat
```

Agar siz Elastic Stack-ni to'g'ri sozlagan bo'lsangiz, Filebeat tizim logi va avtorizatsiya loglarini Logstash-ga jo'natishni boshlaydi, keyin esa bu ma'lumotlarni Elasticsearch-ga yuklaydi.

Elasticsearch haqiqatan ham ushbu ma'lumotlarni olayotganligini tekshirish uchun Filebeat indeksini ushbu buyruq bilan so'rang:

```bash
curl -XGET 'http://localhost:9200/filebeat-*/_search?pretty'
```

```json
{
  "took" : 16,
  "timed_out" : false,
  "_shards" : {
    "total" : 2,
    "successful" : 2,
    "skipped" : 0,
    "failed" : 0
  },
  "hits" : {
    "total" : {
      "value" : 8325,
      "relation" : "eq"
    },
    "max_score" : 1.0,
    "hits" : [
      {
        "_index" : "filebeat-7.17.20-2024.05.01",
        "_type" : "_doc",
        "_id" : "rBm1NI8Ba_iulf7QZROj",
        "_score" : 1.0,
        "_source" : {
          "agent" : {
            "hostname" : "elk",
            "name" : "elk",
            "id" : "25293b23-06d1-48cc-b07d-99fd73ddced0",
            "ephemeral_id" : "093e3563-21c7-4b8d-9003-63d3ab4de274",
            "type" : "filebeat",
            "version" : "7.17.20"
          },
          "process" : {
            "name" : "useradd",
            "pid" : 575
          },
```