import { Callout } from "nextra-theme-docs";

# Kubernetes Arxitekturasi

![k8s](/images/tutorials/k8s/architecture/1.jpg)

<Callout type="info" emoji="">
**Mundarija**

**Kubernetes Arxitekturasi**

* Control Plane
* Worker Node

**Kubernetes Control Plani komponentlari**

* kube-apiserver
* etcd
* kube-scheduler
* Kube Controller Manager
* Cloud Controller Manager (CCM)

**Kubernetes Worker Node komponentlari**

* Kubelet
* Kube proxy
* Container Runtime

**Kubernetes Cluster Addon komponentlari**

* CNI Plugin


* Kubernetes Arxitekturasi boʻyicha tez-tez soʻraladigan savollar
* Kubernetes control planening asosiy maqsadi nima?
* Kubernetes clusteridagi worker nodelarining maqsadi nima?
* Kubernetes-da control plane va worker nodelari o'rtasidagi aloqa(communication) qanday ta'minlanadi?
* Kubernetesdagi `etcd` key-value storening maqsadi nima?
* Agar etcd ishlamay qolsa, Kubernetes applicationlari bilan nima sodir bo'ladi?
* Xulosa
</Callout>

## Kubernetes Arxitekturasi

Quyidagi Kubernetes arxitektura diagrammasi Kubernetes clusterining barcha komponentlarini va tashqi tizimlarning Kubernetes clusteriga qanday ulanishini ko'rsatadi.

![k8s](/images/tutorials/k8s/architecture/3.png)

Kubernetes haqida tushunishingiz kerak bo'lgan birinchi va eng muhim narsa - bu `distributed system`(taqsimlangan tizim). Ya'ni, u tarmoq orqali turli serverlar bo'ylab tarqalgan bir nechta komponentlarga ega. Bu serverlar virtual mashinalar(vm virtual machine) yoki bare metal serverlar bo'lishi mumkin. Biz uni `Kubernetes Clusteri` deb ataymiz.

Kubernetes clusteri control plane nodelari va worker nodelardan iborat.

![k8s](/images/tutorials/k8s/architecture/4.png)

Quyidagi rasmda Kubernetes Container tashuvchi kema sifatida ko'rsatilgan. 

### Control Plane

Control plane konteyner orkestratsiyasi(container orchestration) va clusterning kerakli stateini(state) saqlab turish uchun javobgardir. U quyidagi tarkibiy qismlarga ega.

<Callout type="info" emoji="">
* kube-apiserver
* etcd
* kube-scheduler
* kube-controller-manager
* cloud-controller-manager
</Callout>

### Worker Node

Worker nodelari konteynerlashtirilgan applicationlarni(ilovala) ishga tushirish uchun javobgardir. Worker node quyidagi komponentlarga ega.

<Callout type="info" emoji="">
* kubelet
* kube-proxy
* Container runtime
</Callout>

## Kubernetes Control Plane Komponentlari

Birinchidan, har bir control plane komponentini va har bir komponent ortidagi muhim tushunchalarni ko'rib chiqaylik.

###  kube-apiserver

`kube-api` serveri Kubernetes API-ni ochib(expose) beruvchi Kubernetes clasterining central hubidir. Oxirgi foydalanuvchilar va boshqa cluster komponentlari API serveri orqali cluster bilan gaplashadi. Juda kamdan-kam hollarda monitoring tizimlari va uchinchi tomon xizmatlari cluster bilan o'zaro aloqa qilish uchun API serverlari bilan gaplashishi mumkin. Shunday qilib, siz clusterni boshqarish uchun `kubectl` dan foydalansangiz, backendda siz `HTTP REST API` orqali API serveri bilan bog'lanasiz. Biroq, scheduler(scheduler), controller va boshqalar kabi ichki cluster komponentlari `gRPC` yordamida API serveri bilan gaplashadi. API serveri va clusterdagi boshqa komponentlar o'rtasidagi aloqa clusterga ruxsatsiz kirishni oldini olish uchun `TLS` orqali amalga oshiriladi.

![k8s](/images/tutorials/k8s/architecture/2.png)

Kubernetes `api-server`i quyidagilar uchun javobgardir

* API management(boshqaruvi): Cluster API so'nggi nuqtasini ochib beradi va barcha API so'rovlarini bajaradi.
* Autentifikatsiya (client sertifikatlari, tashuvchi tokenlari(bearer token) va HTTP asosiy autentifikatsiyasidan foydalanish) va avtorizatsiya (ABAC va RBAC evaluation).
* API soʻrovlarini(request) qayta ishlash va API obʼyektlari kabi pods, servicelar va boshqalar uchun maʼlumotlarni tekshirish (Validation and Mutation Admission Controllers)
* Bu etcd bilan aloqa(communicate) qiladigan yagona komponent.
* api-server control plane va worker node komponentlari o'rtasidagi barcha jarayonlarni(process) muvofiqlashtiradi.
* api-serverda o'rnatilgan bastion apiserver proksi-server mavjud. Bu API server jarayonining bir qismidir. U asosan clusterdan tashqaridan ClusterIP servicelariga kirishni ta'minlash uchun ishlatiladi, garchi bu servicelar odatda faqat clusterning o'zida mavjud bo'lsa ham.

### etcd

![k8s](/images/tutorials/k8s/architecture/5.png)
Kubernetes distributed system bo'lib, uning distributed(taqsimlangan) tabiatini qo'llab-quvvatlaydigan `etcd` kabi samarali distributed databaselar bazasiga muhtoj. U ham backend xizmatini kashf qilish, ham ma'lumotlar bazasi sifatida ishlaydi. Siz uni Kubernetes clusterining miyasi deb atashingiz mumkin.

[`etcd` open source](https://github.com/etcd-io/etcd) kuchli izchil, distributed key-value storedir. Xo'sh, bu nimani anglatadi?

**Strongly consistent** Agar nodega yangilanish amalga oshirilsa, strong consistency uning clusteridagi barcha boshqa nodelarga darhol yangilanishini ta'minlaydi. Bundan tashqari, agar siz CAP teoremasiga qarasangiz, kuchli mustahkamlik va & Bo'limga chidamlilik bilan 100% mavjudlikka erishish mumkin emas.

**Distributed** etcd bir nechta nodelarda cluster sifatida mustahkamlikdan voz kechmasdan ishlash uchun mo'ljallangan.

**Key Value Store** ma'lumotlarni keylar va valuelar sifatida saqlaydigan aloqador bo'lmagan ma'lumotlar bazasi. Shuningdek, u key-valueli API-ni ham ochib beradi. Ma'lumotlar ombori [BoltDB](https://github.com/etcd-io/bbolt) forki bo'lgan B[boltDB](https://github.com/etcd-io/bbolt) ustiga qurilgan.

etcd mustahkam mustahkamlik va mavjudlik uchun `raft consensus` algoritmidan foydalanadi. U yuqori darajadagi mavjudlik va nodelarning nosozliklariga dosh berish uchun leader-member uslubida ishlaydi.

Xo'sh, etcd Kubernetes bilan qanday ishlaydi?

Oddiy qilib aytganda, kubernetes object detaillarini olish uchun kubectl dan foydalansangiz, uni etcd dan olasiz. Bundan tashqari, objectni `pod` kabi deploy qilganingizda, yozuv etcd da yaratiladi.

Xulosa qilib aytganda, bu yerda siz etcd haqida bilishingiz kerak bo'lgan narsalar.

* etcd barcha konfiguratsiyalar, statelar va Kubernetes objectlari metama'lumotlarini (podlar, secretlar, daemonsetlar, deploymentlar, configmaplar, statefulset va boshqalarni) saqlaydi.
* etcd clientga Watch() API yordamida eventlarga subscribe qilish imkonini beradi. Kubernetes api-server object statetidagi(state) o'zgarishlarni(change) kuzatish uchun etcd-ning `watch` funksiyasidan foydalanadi.
* etcd gRPC yordamida key-value API-ni ochib beradi. Bundan tashqari, gRPC gatewayi barcha HTTP API chaqiruvlarini gRPC messagelariga tarjima qiladigan RESTful proksi-server hisoblanadi. Bu uni Kubernetes uchun ideal ma'lumotlar bazasiga aylantiradi.
* etcd barcha objectlarni `/registry` directory keyi ostida  key-value formatida saqlaydi. Masalan, default namespacedagi Nginx nomli pod haqida ma'lumotni `/registry/pods/default/nginx` ostida topish mumkin.

![k8s](/images/tutorials/k8s/architecture/6.png)


Bundan tashqari, etcd control planedagi yagona `Statefulset` komponentidir.

### kube-scheduler

kube-scheduler worker nodelarida Kubernetes podlarini rejalashtirish(scheduling) uchun javobgardir. Siz podni o'rnatganingizda, siz protsessor, xotira, affinity, nosozliklar(taints) yoki bardoshlik(tolerations), priority(ustuvorlik), persistent volume(PV) kabi pod talablarini belgilaysiz. Schedulerning asosiy vazifasi cretae so'rovini(requestini) aniqlash va talablarga javob beradigan pod uchun eng yaxshi nodeni tanlashdir.  Quyidagi rasmda schedulerni qanday ishlashining yuqori darajadagi umumiy ko'rinishi ko'rsatilgan.

![k8s](/images/tutorials/k8s/architecture/7.png)

Kubernetes clusterida bir nechta worker nodelari bo'ladi. Xo'sh, qanday qilib scheduler barcha worker nodelardan nodeni tanlaydi?

Bu yerda scheduler qanday ishlaydi.

1. Eng yaxshi nodeni tanlash uchun kube-scheduler filtrlash va baholash(scoring) operatsiyalaridan foydalanadi.

2. Filtrlashda scheduler podni rejalashtirish mumkin bo'lgan eng mos nodelarni topadi. Misol uchun, podni ishga tushirish uchun resurs mavjud bo'lgan besh worker mode mavjud bo'lsa, u barcha besh nodeni tanlaydi. Agar nodelar bo'lmasa, pod rejalashtirilmaydi va rejalashtirish navbatiga o'tkaziladi. Agar bu katta cluster bo'lsa, aytaylik, 100 worker modelari va scheduler barcha nodelarni takrorlamaydi. `percentageOfNodesToScore` deb nomlangan scheduler konfiguratsiya parametri mavjud. Default qiymat odatda 50% ni tashkil qiladi. Shunday qilib, u nodelarning 50% dan ortig'ini round-robin rejimda takrorlashga harakat qiladi. Agar worker modelar bir nechta zonalar bo'ylab tarqalgan bo'lsa, scheduler turli zonalardagi nodelarni takrorlaydi. Juda katta clusterlar uchun standart `percentageOfNodesToScore` 5% ni tashkil qiladi.

3. Baholash(scoring) bosqichida scheduler filtrlangan worker nodelariga ball qo'yish orqali nodelarni tartiblaydi. Scheduler bir nechta scheduling pluginlariga chaqiruv qilish orqali reytingni amalga oshiradi. Nihoyat, podni scheduling(rejalashtirish) uchun eng yuqori darajaga ega worker node tanlanadi. Agar barcha nodelar bir xil darajaga ega bo'lsa, node tasodifiy tanlanadi.

4. Node tanlangandan so'ng, scheduler API serverida binding event yaratadi. Binding event pod va nodeni bog'lashni anglatadi.

**Scheduler haqida bilish kerak bo'lgan narsalar.**

* Bu API serverida pod create(yaratish) eventlarini tinglaydigan controller.
* Scheduler ikki bosqichdan iborat. `Scheduling sikli` va `Binding sikli`. Birgalikda u scheduling konteksti deb ataladi. Scheduling sikli worker nodeni tanlaydi va binding sikli bu o'zgarishni clusterga qo'llaydi.

* Scheduler har doim yuqori high-priority podlarni scheduling(rejalashtirish) uchun low-priority podlardan oldinroq joylashtiradi. Bundan tashqari, ba'zi hollarda, pod tanlangan nodeda ishlay boshlagandan so'ng, poddan chiqarib yuborilishi yoki boshqa nodelarga ko'chirilishi mumkin. Agar siz ko'proq tushunishni istasangiz, [Kubernetes pod priority](https://devopscube.com/pod-priorityclass-preemption/) qo'llanmasini o'qib ko'ring.

* Siz maxsus schedulerlarni yaratishingiz va nativ scheduler bilan bir qatorda clusterda bir nechta schedulerlarni ishga tushirishingiz mumkin. Podni deploy qilganizda, pod manifestida maxsus schedulerni belgilashingiz mumkin. Shunday qilib, scheduling qarorlari custom scheduler mantig'i asosida qabul qilinadi.

* Schedulerda ulanadigan scheduling framework mavjud. Ya'ni, siz o'zingizning custom plugingizni scheduling workflowiga qo'shishingiz mumkin.

![k8s](/images/tutorials/k8s/architecture/9.jpg)

### Kube Controller Manager

![k8s](/images/tutorials/k8s/architecture/8.jpg)


Controller nima? [Controllerlar](https://kubernetes.io/docs/concepts/architecture/controller/) infinite control sikllarini ishga tushiradigan dasturlardir. Ya'ni, u doimiy ishlaydi va ob'ektlarning actual va kerakli statetini kuzatadi. Actual va kerakli statetida farq bo'lsa, kubernetes resource/object kerakli statetida bo'lishini ta'minlaydi.

Kubernetes-da controllerlar clusteringiz statetini(holatini) kuzatadigan, keyin kerak bo'lganda o'zgartirishlar kiritadigan yoki so'raydigan boshqaruv sikllari. Har bir controller joriy cluster statetini kerakli statega yaqinlashtirishga harakat qiladi.

Aytaylik, siz deployment create qilmoqchisiz, manifest YAML faylida kerakli stateni belgilaysiz (deklarativ yondashuv). Masalan, 2 replica(nusxa), bitta volume mount qilish, configmap va boshqalar.